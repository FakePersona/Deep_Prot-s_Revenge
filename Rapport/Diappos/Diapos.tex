% $Header: /home/vedranm/bitbucket/beamer/solutions/conference-talks/conference-ornate-20min.en.tex,v 90e850259b8b 2007/01/28 20:48:30 tantau $

\documentclass{beamer}

% This file is a solution template for:

% - Talk at a conference/colloquium.
% - Talk length is about 20min.
% - Style is ornate.



% Copyright 2004 by Till Tantau <tantau@users.sourceforge.net>.
%
% In principle, this file can be redistributed and/or modified under
% the terms of the GNU Public License, version 2.
%
% However, this file is supposed to be a template to be modified
% for your own needs. For this reason, if you use this file as a
% template and not specifically distribute it as part of a another
% package/program, I grant the extra permission to freely copy and
% modify this file as you see fit and even to delete this copyright
% notice. 


\mode<presentation>
{
  \usetheme{AnnArbor}
  % or ...

  \setbeamercovered{transparent}
  % or whatever (possibly just delete it)
}


\usepackage[francais]{babel}
% or whatever

\usepackage[utf8]{inputenc}
% or whatever

\usepackage{times}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.


\title[Représentation latente de protéines] % (optional, use only with long paper titles)
{Apprentissage profond et représentation latente de séquences peptidiques} 

\author[Rémy Sun]{Rémy Sun \and sous la direction de François Coste} % (optional, use only with lots of authors)

\institute[ENS Rennes] % (optional, but mostly needed)
{
  

  \begin{columns}
    \column{0.45\linewidth}
    \center
    \includegraphics[scale=0.15]{../Figures/ENS}\\
    Département d'informatique\\
    ENS Rennes
    
    \column{0.45\linewidth}
    \center
    \includegraphics[scale=0.7]{../Figures/dyliss}\\

    Equipe Dyliss\\
    IRISA
  \end{columns}

}
% - Use the \inst command only if there are several affiliations.
% - Keep it simple, no one is interested in your street address.

\date[XTRA 2016] % (optional, should be abbreviation of conference name)
{XTRA 2016}
% - Either use conference name or its abbreviation.
% - Not really informative to the audience, more for people (including
%   yourself) who are reading the slides online

\subject{Theoretical Computer Science}
% This is only inserted into the PDF information catalog. Can be left
% out. 



% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% \pgfdeclareimage[height=0.5cm]{university-logo}{university-logo-filename}
% \logo{\pgfuseimage{university-logo}}



% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
\AtBeginSubsection[]
{
  \begin{frame}<beamer>{Plan}
    \tableofcontents[currentsection,currentsubsection]
  \end{frame}
}


% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command: 

%\beamerdefaultoverlayspecification{<+->}


\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Quelles applications pour les protéines?}
  \tableofcontents[pausesections]
  % You might wish to add the option [pausesections]
\end{frame}


% Structuring a talk is a difficult task and the following structure
% may not be suitable. Here are some rules that apply for this
% solution: 

% - Exactly two or three sections (other than the summary).
% - At *most* three subsections per section.
% - Talk about 30s to 2min per frame. So there should be between about
%   15 and 30 frames, all told.

% - A conference audience is likely to know very little of what you
%   are going to talk about. So *simplify*!
% - In a 20min talk, getting the main ideas across is hard
%   enough. Leave out details, even if it means being less precise than
%   you think necessary.
% - If you omit details that are vital to the proof/implementation,
%   just say so once. Everybody will be happy with that.

\section{Apprentissage profond?}

\subsection{Pourquoi l'apprentissage \og profond\fg?}

\begin{frame}{Une unité de calcul à paramètres optimisables}
  % - A title should summarize the slide in an understandable fashion
  %   for anyone how does not follow everything on the slide itself.

  \begin{columns}
    \column{0.38\linewidth}
    \begin{figure}
      \centering
      \includegraphics[scale=0.17]{../Figures/Neuron}
    \end{figure}

    \column{0.5\linewidth}
    \begin{itemize}
    \item Entrée $A$, poids $W$, biais $b$
    \item Transformation linéaire $WA + b$
    \item Activation non-linéaire $f$
    \item Apprentissage de $W$ et $b$
      \begin{itemize}
      \item Par rétropropagation sur la distance à l'objectif
      \end{itemize}
    \end{itemize}
  \end{columns}

\end{frame}

\begin{frame}{Représentation hiérarchiques par couches}
  % - A title should summarize the slide in an understandable fashion
  %   for anyone how does not follow everything on the slide itself.

  \begin{columns}
    \column{0.5\linewidth}
    \only<1>
    {
      \begin{figure}
        \centering
        \includegraphics[scale=0.1750]{../Figures/Shallow}
      \end{figure}
    }
    \only<2>
    {
      \begin{figure}
        \centering
        \includegraphics[scale=0.1750]{../Figures/Deep}
      \end{figure}
    }

    \column{0.4\linewidth}
    \begin{itemize}
    \item Plusieurs couches de neurones
    \item Hiérarchie: plusieurs niveaux de représentations
    \item Evanouissement de gradient
    \item Grands ensembles d'entraînement
    \end{itemize}
  \end{columns}

\end{frame}

\subsection{Entraînement non-supervisé: Autoencodeurs et représentations latentes}

\begin{frame}{Acquérir des représentations latentes intéressantes}
  % - A title should summarize the slide in an understandable fashion
  %   for anyone how does not follow everything on the slide itself.

  \begin{columns}
    \column{0.45\linewidth}
    \begin{figure}
      \centering
      \includegraphics[scale=0.8]{../Figures/DenseAuto}
    \end{figure}

    \column{0.5\linewidth}
    \begin{itemize}
    \item Non supervisé
    \item Encodage/Décodage
    \item \textbf{Représentation latente}
    \item Eviter d'encoder l'identité\pause
      \begin{itemize}
      \item Compression\pause
      \item Bruitage\pause
      \item Régularisation
      \end{itemize}
    \end{itemize}
  \end{columns}
\end{frame}

\subsection{Architectures standards}

\begin{frame}{Réseaux Convolutionnels: recherche de caractéristique}
  % - A title should summarize the slide in an understandable fashion
  %   for anyone how does not follow everything on the slide itself.

    \begin{figure}
      \centering
      \includegraphics[scale=0.7]{../Figures/conv}
    \end{figure}

    \begin{itemize}
    \item Filtres de caractéristiques
    \item Permet d'isoler des caractéristiques locales
    \end{itemize}
\end{frame}

\begin{frame}{Réseaux récurrents: tenir compte de l'ordre d'apparition}
  % - A title should summarize the slide in an understandable fashion
  %   for anyone how does not follow everything on the slide itself.
  \begin{columns}
    \column{0.4\linewidth}
    \only<1>
    {
      \begin{figure}
        \centering
        \includegraphics[scale=0.15]{../Figures/Recurrent}
      \end{figure}
    }
    \only<2>
    {
      \begin{figure}
        \centering
        \includegraphics[scale=0.15]{../Figures/LSTM}
      \end{figure}
    }

    \column{0.5\linewidth}
    \begin{itemize}
    \item Dépendance temporelles
    \item Sortie + état caché persistant (boucle de rétroaction)
    \item Réseau \og profond\fg à une couche
    \item Pas de dépendances hiérarchiques\pause
    \item Unité LSTM (Long Short-Term Memory)
    \end{itemize}
  \end{columns}
\end{frame}


\section{Application aux protéines}

\subsection{Qu'est-ce-qu'une protéine?}

\begin{frame}{Une molécule chimique}
  % - A title should summarize the slide in an understandable fashion
  %   for anyone how does not follow everything on the slide itself.
  \begin{figure}
    \centering
    \includegraphics[scale=0.3]{../Figures/prot}
  \end{figure}
    \begin{itemize}
    \item Acide aminés: molécules chimiques
    \item Structure primaire: chaîne d'acides aminés
    \item Structure secondaire: structures locales formé par les acides
      (hélices-$\alpha$, brins-$\beta$, ...)
    \item Structure tertiaire: forme tridimensionnelle
    \end{itemize}
\end{frame}

\subsection{Etat de l'art}

\begin{frame}{Peu de travaux concernant les protéines}
  % - A title should summarize the slide in an understandable fashion
  %   for anyone how does not follow everything on the slide itself.

      \begin{itemize}
      \item Succès en:\pause
        \begin{itemize}
        \item Reconnaissance d'image, langages naturels,
          prédiction de sentiments, données bio-médicales,
          représentation, ...\pause
        \end{itemize}
      \end{itemize}


      \begin{itemize}
      \item Protéines:
        \begin{itemize}
        \item Prédiction de structures secondaires et locales\pause
          \begin{itemize}
          \item Heffernan R. et al. 2015 Improving prediction of secondary
            structure, local backbone angles, and solvent accessible surface
            area of proteins by iterative deep learning. \pause
          \item Spencer M et al. 2015 A Deep Learning Network Approach to ab
            initio Protein Secondary Structure Prediction\pause
          % \item Lena PD et al. 2012 Deep architectures for protein contact
          %   map prediction. \pause
          \item ...\pause
          \end{itemize}
        \item Classification de protéines selon différents critéres\pause
          \begin{itemize}
          \item Jian-Wei L. et al. 2013 Predicting protein structural classes with autoencoder neural networks
          \end{itemize}
        \end{itemize}
      \end{itemize}


\end{frame}

\subsection{Traiter des séquences peptidiques}

\begin{frame}{Traiter des fragments courts pour étudier des chaînes longues}
  % - A title should summarize the slide in an understandable fashion
  %   for anyone how does not follow everything on the slide itself.

    \begin{itemize}
    \item Tâche sur une chaîne longue: prédiction de classe structurale (SCOPe
      2.6, 40\%)
      \begin{itemize}
      \item Travaux usuels: représentation par vecteur de fréquence des
        protéines augmenté
      \item Découpage de la chaîne en fragments courts
      \end{itemize}
    \item Etude sur les séquences peptidiques
    \item Représentation de l'acide $a_i$ par $V = (v_k)$ où $v_i = 1$ et $v_k =
      0 (k\ne i)$
    \end{itemize}
\end{frame}

\subsection{Architectures entrainées \& résultats}

\begin{frame}{Autoencodeurs}
  % - A title should summarize the slide in an understandable fashion
  %   for anyone how does not follow everything on the slide itself.

  \begin{columns}
    \column{0.35\linewidth}
    \begin{figure}
      \centering
      \includegraphics[scale=0.17]{../Figures/EncoDeco}
    \end{figure}

    \column{0.6\linewidth}
    \begin{itemize}
    \item Entraînement sur des fragments de taille 11
    \item Augmentation de la taille de l'ensemble d'entraînement de 13500 à 700
      000
    \item Espace latent à 20 dimensions
    \item Encodeur récurrent à 3 couches
    \item Décodeur récurrent
    \end{itemize}
  \end{columns}
  
\end{frame}

\begin{frame}{Les représentation latentes présentent des corrélations remarquables}
  % - A title should summarize the slide in an understandable fashion
  %   for anyone how does not follow everything on the slide itself.

  \only<1>
  {
    \begin{figure}
      \centering
      \includegraphics[scale=0.27]{../Figures/SingleOneRecHeatf1}
      %\caption{Corrélations entre représentation latente et propriétés physico-chimiques}
    \end{figure}
  }
  \only<2>
  {
    \begin{figure}
      \centering
      \includegraphics[scale=0.27]{../Figures/SingleOneRecHeatf2}
      %\caption{Corrélations entre représentation latente et propriétés physico-chimiques}
    \end{figure}
  }
  \only<3>
  {
    \begin{figure}
      \centering
      \includegraphics[scale=0.27]{../Figures/SingleOneRecHeatf3}
      %\caption{Corrélations entre représentation latente et propriétés physico-chimiques}
    \end{figure}
  }

    \begin{itemize}
    \item Dimensions liées dans l'espace latent\pause
    \item Corrélation de coordonnées à l'hydropathie, à la charge ...\pause
    \item Pas de corrélation à la structure secondaire observées
    \end{itemize}
  
\end{frame}


\begin{frame}{Classificateur de classe structurales}
  % - A title should summarize the slide in an understandable fashion
  %   for anyone how does not follow everything on the slide itself.

  \begin{columns}
    \column{0.45\linewidth}
    \begin{figure}
      \centering
      \includegraphics[scale=0.16]{../Figures/Classd}
    \end{figure}

    \column{0.5\linewidth}
    \begin{itemize}
    \item Tâche: classifier les classes structurales des protéines
    \item Classificateur convolutionnel
    \item Premières couches pré-entraînées
    \item Validation de la représentation latente acquise
    \end{itemize}
  \end{columns}

 \end{frame}


\begin{frame}{Les représentations latentes sont exploitables par un
    classificateur structural}
  % - A title should summarize the slide in an understandable fashion
  %   for anyone how does not follow everything on the slide itself.

  \begin{columns}
    \column{0.45\linewidth}
    \begin{figure}
      \centering
      \includegraphics[scale=0.25]{../Figures/SupClass}
    \end{figure}

    \column{0.45\linewidth}
    \begin{figure}
      \centering
      \includegraphics[scale=0.25]{../Figures/SpeClass}
    \end{figure}

  \end{columns}

    \begin{itemize}
     
    \item Comparaison favorable au même classificateur non pré-entrainé:
      \begin{itemize}
      \item Atteinte plus rapide de la précision maximale\pause
      \item Précision maximale plus élevée\pause
      \end{itemize}
    \item Pertinence de la représentation latente
    \end{itemize}

 \end{frame}

% \begin{frame}{Pistes de recherche}
%   % - A title should summarize the slide in an understandable fashion
%   %   for anyone how does not follow everything on the slide itself.

%     \begin{itemize}
%     \item Architectures d'auto-encodeurs à attention\pause
%     \item Acquisition d'une représentation pertinente des acides aminés\pause
%     \item Etude plus approfondie des hyper-paramètres\pause
%     \item Hiérarchiser les caractéristiques à utiliser en apprentissage\pause
%     \item Initialisation couche par couche?
%     \end{itemize}
%  \end{frame}


\section*{Conclusion}

\begin{frame}{Résumé}

  % Keep the summary *very short*.
  \begin{itemize}
  \item
    L'apprentissage profond permet de \alert{détecter des structure
      hiérarchiques ou temporelles}.\pause
  \item
    Problème particulier: Pas assez \alert{d'exemples labélisés} et \alert{chaînes très longues}.\pause
  \item
    Apparition de \alert{corrélations} entre la représentation latente et des
    caractéristiques des séquences peptidiques.\pause
  \end{itemize}
  
  % The following outlook is optional.
  \vskip0pt plus.5fill
  \begin{itemize}
  \item
    Perspectives\pause
    \begin{itemize}
    \item
      Utilisation d'autres architectures utilisées en langages naturels.\pause
    \item
      Influence des hyper paramètres.\pause
    \end{itemize}
  \end{itemize}
\end{frame}



% All of the following is optional and typically not needed. 
\appendix

\section<presentation>*{\appendixname}
\subsection<presentation>*{For Further Reading}

\begin{frame}{Eviter le sur-entraînement}
  % - A title should summarize the slide in an understandable fashion
  %   for anyone how does not follow everything on the slide itself.

  \begin{columns}
    \column{0.5\linewidth}
    \begin{figure}
      \centering
      \includegraphics[scale=0.3]{../Figures/dropout}
    \end{figure}

    \column{0.45\linewidth}
    \begin{itemize}
    \item Désactiver aléatoirement des neurones\pause
    \item Eliminer la concentration d'information\pause
    \item Faire travailler tout le réseau\pause
    \item Généraliser la représentation apprise\pause
    \item Permet d'entraîner ad nauseam
    \end{itemize}
  \end{columns}
\end{frame}


\end{document}
